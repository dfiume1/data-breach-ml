{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the machine learning work for this project. A preprocessing, splitting, and CV pipeline are created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Shape:  (24586, 29)\n"
     ]
    }
   ],
   "source": [
    "# Load the data (raw / feature engineered)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = \"/Users/djfiume/Desktop/DSI/1030/data-breach-ml\"\n",
    "data = pd.read_csv(path + \"/data/cleaned_raw_data.csv\", index_col=0)\n",
    "\n",
    "data.head()\n",
    "print(\"Full Data Shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix size: (24586, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    24586.000000\n",
       "mean         2.383157\n",
       "std          1.519120\n",
       "min          0.000000\n",
       "25%          0.903090\n",
       "50%          2.586024\n",
       "75%          3.464526\n",
       "max          9.477121\n",
       "Name: Max Records Impacted, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['Max Records Impacted']\n",
    "\n",
    "data.drop(columns=['Max Records Impacted'],inplace=True)\n",
    "# the unprocessed feature matrix\n",
    "X = data\n",
    "print(f'feature matrix size: {X.shape}')\n",
    "# the feature names\n",
    "ftrs = data.columns\n",
    "\n",
    "# MODEL MAKES MORE SENSE TO PREDICT THE LOGS\n",
    "# ex: predicting 100 records for true 10,000 should be the same as predicting 1,000,000 for true 10,000\n",
    "y = y+1\n",
    "y = np.log10(y)\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the Features\n",
    "\n",
    "cat_ftrs = [\"Breach Type\", \"Source\", \"Organization Type\", \"breach_location_state\"]\n",
    "\n",
    "num_ftrs = [\"Reported Year\", \"Reported Month\", \"Days Until Reported\", \"Length of Breach (Days)\", \"IDENTIFIER\",\\\n",
    "            \"COMMERCIAL\", \"BIOMETRIC\", \"HEALTH\", \"INTERNETDATA\", \"GEOLOCATION\", \"RECORDING\", \"EMPLOYMENT\",\\\n",
    "            \"EDUCATION\", \"SENSITIVE-GOV\", \"SENSITIVE-LOGIN\", \"SENSITIVE-GEOLOCATION\", \"SENSITIVE-PROTECTED\",\\\n",
    "            \"SENSITIVE-COMMUNICATIONS\", \"SENSITIVE-DNA\", \"Type UNKN\", \"ENCRYPTED\", \"ENCRYPTED-WITH-DECRYPTIONKEY\",\\\n",
    "            \"UNENCRYPTED\", \"Encrypt UNKN\"]\n",
    "\n",
    "# From the Data README \n",
    "# info_types = [\"IDENTIFIER\", \"COMMERCIAL\", \"BIOMETRIC\", \"HEALTH\", \"INTERNETDATA\", \"GEOLOCATION\", \"RECORDING\", \"EMPLOYMENT\", \"EDUCATION\", \"SENSITIVE-GOV\", \"SENSITIVE-LOGIN\", \"SENSITIVE-GEOLOCATION\", \"SENSITIVE-PROTECTED\", \"SENSITIVE-COMMUNICATIONS\", \"SENSITIVE-DNA\", \"UNKN\"]\n",
    "# encrypt_types = [\"ENCRYPTED\", \"ENCRYPTED-WITH-DECRYPTIONKEY\", \"UNENCRYPTED\"]\n",
    "# breach_types = [\"CARD\", \"HACK\", \"INSD\", \"PHYS\", \"PORT\", \"STAT\", \"DISC\", \"UNKN\"]\n",
    "# org_types = [\"BSF\", \"BSO\", \"BSR\", \"EDU\", \"GOV\", \"MED\", \"NGO\", \"UNKN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Preprocessor \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# one-hot encoder\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='UNKN')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    # This is only for the engineered date features. All other features have no nulls\n",
    "    # Assume no date breach end date = 0 breach length \n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)), \n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "\n",
    "def MLpipe_KFold_RMSE(X, y, preprocessor, ML_algo, param_grid, num_seeds):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 5 folds to other.\n",
    "    The RMSLE (Root Mean Squared Log Error) is minimized in cross-validation.\n",
    "\n",
    "    Args:\n",
    "    X : DataFrame or ndarray\n",
    "        Features for model training.\n",
    "    y : DataFrame or ndarray\n",
    "        Labels/target for model training.\n",
    "    preprocessor : sklearn transformer\n",
    "        The preprocessor object (e.g., ColumnTransformer).\n",
    "    ML_algo : sklearn estimator\n",
    "        The machine learning algorithm (e.g., RandomForestRegressor).\n",
    "    param_grid : dict\n",
    "        Grid of parameters for GridSearchCV.\n",
    "    num_seeds : int\n",
    "        Number of random seeds to use for cross-validation.\n",
    "    save_model : bool, default False\n",
    "        Whether to save the best model and predictions.\n",
    "    name: string, default None\n",
    "        What the model name is to name the filenames\n",
    "\n",
    "    Returns:\n",
    "    test_scores : list\n",
    "        List of test RMSE scores.\n",
    "    best_models : list\n",
    "        List of best model parameters from GridSearchCV.\n",
    "    r2_scores : list\n",
    "        List of R² scores for the test set.\n",
    "    '''\n",
    "     \n",
    "    test_scores = []\n",
    "    r2_scores = []\n",
    "    best_models = []\n",
    "\n",
    "    # Loops through 5 different random states. This is to ensure the best model\n",
    "    # on average is picked. They are fixed for reproducability. \n",
    "    random_states = np.linspace(0,100000, num_seeds, dtype=int)\n",
    "    \n",
    "    for i in range(num_seeds): \n",
    "\n",
    "        # Split Data Randomly \n",
    "        X_other, X_test, y_other, y_test = (train_test_split(X, \n",
    "            y, train_size=0.8, random_state=random_states[i]))\n",
    "\n",
    "        # Fits a model using GridSearchCV with KFold and the predefined Preprocessor \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=random_states[i]) \n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', ML_algo)\n",
    "        ])\n",
    "        \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, \n",
    "                            scoring=\"neg_root_mean_squared_error\", cv=kf, verbose=2) # you can turn this off\n",
    "        grid_search.fit(X_other, y_other)\n",
    "\n",
    "        # Calculate the model's error on the test set \n",
    "        y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        print(rmse)\n",
    "        print(r2)\n",
    "        test_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        best_models.append(best_params)\n",
    "\n",
    "        # Only need to print this once, can use for debugging\n",
    "        # if random_state == 0:\n",
    "            # print(\"Train_Inputs Shape:\", X_other.shape)\n",
    "            # print(\"Train_Labels Shape:\", y_other.shape)\n",
    "            # print(\"Test_Inputs Shape:\", X_test.shape)\n",
    "            # print(\"Test_Labels Shape:\", y_test.shape)\n",
    "\n",
    "            # print(\"GridSearch\", grid_search.cv_results_)\n",
    "        \n",
    "        # print(\"Random State: \", random_state, \" RMSE: \", rmse, \n",
    "        #       \" Best Model:\", best_params)\n",
    "\n",
    "    print(\"RMSE: \", test_scores, \"\\n Models: \", best_models, \"r2 score:\", r2_scores)\n",
    "    return test_scores, best_models, r2_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the pipeline on regression algorithims for CV / hyperparamter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune individual models in the first cell. Only run the last cell when you have narrowed down your search (it takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "[CV] END ...............................model__n_neighbors=1; total time=   0.3s\n",
      "[CV] END ...............................model__n_neighbors=1; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=1; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=1; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=1; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=3; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=3; total time=   0.3s\n",
      "[CV] END ...............................model__n_neighbors=3; total time=   0.3s\n",
      "[CV] END ...............................model__n_neighbors=3; total time=   0.3s\n",
      "[CV] END ...............................model__n_neighbors=3; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=5; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=5; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=5; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=5; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=5; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=7; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=7; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=7; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=7; total time=   0.2s\n",
      "[CV] END ...............................model__n_neighbors=7; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=10; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=10; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=10; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=10; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=10; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=15; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=15; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=15; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=15; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=15; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=20; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=20; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=20; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=20; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=20; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=25; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=25; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=25; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=25; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=25; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=30; total time=   0.2s\n",
      "[CV] END ..............................model__n_neighbors=30; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=30; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=30; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=30; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=40; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=40; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=40; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=40; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=40; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=50; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=50; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=50; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=50; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=50; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=75; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=75; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=75; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=75; total time=   0.3s\n",
      "[CV] END ..............................model__n_neighbors=75; total time=   0.3s\n",
      "[CV] END .............................model__n_neighbors=100; total time=   0.3s\n",
      "[CV] END .............................model__n_neighbors=100; total time=   0.3s\n",
      "[CV] END .............................model__n_neighbors=100; total time=   0.3s\n",
      "[CV] END .............................model__n_neighbors=100; total time=   0.3s\n",
      "[CV] END .............................model__n_neighbors=100; total time=   0.3s\n",
      "1.1510612070807582\n",
      "0.4165146850425161\n",
      "RMSE:  [1.1510612070807582] \n",
      " Models:  [{'model__n_neighbors': 10}] r2 score: [0.4165146850425161]\n",
      "[{'model__n_neighbors': 10}]\n",
      "kNearestNeighbors RMSE Average:  1.1511\n",
      "kNearestNeighbors RMSE Standard Deviation:  0.0\n",
      "kNearestNeighbors R2 Average:  0.4165\n",
      "kNearestNeighbors R2 Standard Deviation:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Use to determine the hyperparameters for the final run \n",
    "\n",
    "names_list = [\"L1_Linerar_Regression\", # i=0\n",
    "              \"L2_Linerar_Regression\", # 1\n",
    "              \"Elastic-Net_Linerar_Regression\", # 2\n",
    "              \"Random Forest\", # 3\n",
    "              \"SVR\", # 4\n",
    "              \"kNearestNeighbors\", # 5\n",
    "              \"XGBoost\", # 6\n",
    "              \"NN_MLP\"] # 7\n",
    "model_list = [Lasso(max_iter=500), \n",
    "              Ridge(max_iter=500), \n",
    "              ElasticNet(max_iter=500), \n",
    "              RandomForestRegressor(), \n",
    "              SVR(),\n",
    "              KNeighborsRegressor(),\n",
    "              XGBRegressor(),\n",
    "              MLPRegressor(learning_rate=\"adaptive\", batch_size=\"auto\", solver=\"adam\", early_stopping=True)]\n",
    "\n",
    "# adjust the grids as you go \n",
    "model_grids = [{\n",
    "                'model__alpha': np.logspace(-4, -2, 10)},\n",
    "               {\n",
    "                'model__alpha': np.linspace(1, 4, 15)},\n",
    "               {\n",
    "                'model__alpha': np.logspace(-4, -2, 5),\n",
    "                'model__l1_ratio' : np.linspace(0.01,0.99,5)},\n",
    "               {\n",
    "                'model__n_estimators': [100, 150, 200],\n",
    "                'model__max_depth': [10, 15, 20]},\n",
    "               { \n",
    "                'model__gamma': [1e-3, 1e-2, 1e-1, 1e0],\n",
    "                'model__C': [1e-1, 1e0, 1e1, 1e2, 1e3]},\n",
    "               { \n",
    "                'model__n_neighbors': [1,3,5,7,10,15,20,25,30,40,50,75,100]},\n",
    "               {\n",
    "                'model__max_depth': [6], \n",
    "                'model__min_child_weight': [3],  \n",
    "                'model__learning_rate': [0.03],  # Tune these two, then above two, then the below 2 and then gamma\n",
    "                'model__n_estimators': [1000], \n",
    "                'model__subsample': [0.8],  \n",
    "                'model__colsample_bytree': [0.8], \n",
    "                'model__gamma': [0,0.1,0.2]}, \n",
    "                {\n",
    "                'model__hidden_layer_sizes': [(150,2)],\n",
    "                'model__alpha': [0.001, 0.0003, 0.001], \n",
    "                'model__max_iter': [300]}]\n",
    "\n",
    "# Pick a model type, run and print results\n",
    "i = 5\n",
    "num_seeds = 1 # can use 1 to narrow range, otherwise some models (SVM) will take a long time \n",
    "test_scores, best_models, r2_scores = MLpipe_KFold_RMSE(X,y,preprocessor,model_list[i], model_grids[i], num_seeds)\n",
    "print(best_models)\n",
    "print(names_list[i], \"RMSE Average: \", np.round(np.mean(test_scores), 4))\n",
    "print(names_list[i], \"RMSE Standard Deviation: \", np.round(np.std(test_scores), 4))\n",
    "print(names_list[i], \"R2 Average: \", np.round(np.mean(r2_scores), 4))\n",
    "print(names_list[i], \"R2 Standard Deviation: \", np.round(np.std(r2_scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Testing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell takes the chosen hyperparamters and runs the models with an 80/20 split over 5 random seeds. It saves each model and the predictions to results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/djfiume/Desktop/DSI/1030/data-breach-ml\"\n",
    "\n",
    "def MLpipe_Final_RMSE(X, y, preprocessor, ML_algo, param_grid, num_seeds, name=None):\n",
    "    '''\n",
    "    This function splits the data to train/test (80/20). It then trains the model and tests it\n",
    "    for a set number of random seeds, saves the models and predictions, and returns the results  \n",
    "    \n",
    "    Args:\n",
    "    X : DataFrame or ndarray\n",
    "        Features for model training.\n",
    "    y : DataFrame or ndarray\n",
    "        Labels/target for model training.\n",
    "    preprocessor : sklearn transformer\n",
    "        The preprocessor object (e.g., ColumnTransformer).\n",
    "    ML_algo : sklearn estimator\n",
    "        The machine learning algorithm (e.g., RandomForestRegressor).\n",
    "    param_grid : dict\n",
    "        Grid of parameters for GridSearchCV.\n",
    "    num_seeds : int\n",
    "        Number of random seeds to use for cross-validation.\n",
    "    name: string, default None\n",
    "        What the model name is to name the filenames\n",
    "\n",
    "    Returns:\n",
    "    test_scores : list\n",
    "        List of test RMSE scores.\n",
    "    best_models : list\n",
    "        List of best model parameters from GridSearchCV.\n",
    "    r2_scores : list\n",
    "        List of R² scores for the test set.\n",
    "    '''\n",
    "     \n",
    "    test_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "\n",
    "    # Loops through a given number of different random states. This is to ensure the best model\n",
    "    # on average is picked. They are fixed for reproducability (if you choose the same # of seeds). \n",
    "    random_states = np.linspace(0,100000, num_seeds, dtype=int)\n",
    "    \n",
    "    for i in range(num_seeds): \n",
    "\n",
    "        # Split Data Randomly \n",
    "        X_train, X_test, y_train, y_test = (train_test_split(X, \n",
    "            y, train_size=0.8, random_state=random_states[i]))\n",
    "\n",
    "        model = ML_algo.set_params(**param_grid)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Calculate the model's error on the test set \n",
    "        y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        test_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "\n",
    "        # Only need to print this once, can use for debugging\n",
    "        # if random_state == 0:\n",
    "            # print(\"Train_Inputs Shape:\", X_other.shape)\n",
    "            # print(\"Train_Labels Shape:\", y_other.shape)\n",
    "            # print(\"Test_Inputs Shape:\", X_test.shape)\n",
    "            # print(\"Test_Labels Shape:\", y_test.shape)\n",
    "\n",
    "            # print(\"GridSearch\", grid_search.cv_results_)\n",
    "        \n",
    "        # print(\"Random State: \", random_state, \" RMSE: \", rmse, \n",
    "        #       \" Best Model:\", best_params)\n",
    "    \n",
    "        # Save the best model and its predictions\n",
    "        if name is not None:\n",
    "            model_file = path + \"/results/\" + name + str(i) + \".pkl\"\n",
    "            pred_file = path + \"/results/\" + name + str(i) + \".npy\"\n",
    "            joblib.dump(pipeline, model_file)\n",
    "            np.save(pred_file, y_pred)\n",
    "            # print(f\"Best model saved as {model_file}\")\n",
    "            # print(f\"Predictions saved as {pred_file}\")\n",
    "        \n",
    "\n",
    "    print(\"RMSE: \", test_scores, \"r2 score:\", r2_scores)\n",
    "    return test_scores, best_models, r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  [1.1154520499506049, 1.1166574608561253, 1.1406962921669241, 1.147215018568752, 1.1388048638494588] r2 score: [0.4520576008391215, 0.4512836217630314, 0.4447495145680067, 0.4358424124616791, 0.4386164503859119]\n",
      "L1_Linerar_Regression RMSE Average:  1.1318\n",
      "L1_Linerar_Regression RMSE Standard Deviation:  0.0131\n",
      "L1_Linerar_Regression R2 Average:  0.4445\n",
      "L1_Linerar_Regression R2 Standard Deviation:  0.0065\n",
      "RMSE:  [1.1158984289298008, 1.1151074056675285, 1.138904566229831, 1.1459557648552305, 1.1385393229708693] r2 score: [0.4516189644880102, 0.4528059334341582, 0.44649244189670445, 0.43708024081408126, 0.4388782211352066]\n",
      "L2_Linerar_Regression RMSE Average:  1.1309\n",
      "L2_Linerar_Regression RMSE Standard Deviation:  0.0128\n",
      "L2_Linerar_Regression R2 Average:  0.4454\n",
      "L2_Linerar_Regression R2 Standard Deviation:  0.0064\n",
      "RMSE:  [1.115452414526689, 1.1166578733946564, 1.1406986722404302, 1.1472029582277343, 1.1387825661720365] r2 score: [0.4520572426583698, 0.4512832163268107, 0.4447471974949042, 0.43585427405173727, 0.43863843383039935]\n",
      "Elastic-Net_Linerar_Regression RMSE Average:  1.1318\n",
      "Elastic-Net_Linerar_Regression RMSE Standard Deviation:  0.0131\n",
      "Elastic-Net_Linerar_Regression R2 Average:  0.4445\n",
      "Elastic-Net_Linerar_Regression R2 Standard Deviation:  0.0065\n",
      "RMSE:  [1.0311093931840072, 1.0062040085466004, 1.0365749681361005, 1.0387326031972968, 1.0309055895153352] r2 score: [0.5317879555623264, 0.5544668065851672, 0.5414884066375532, 0.5374929977260203, 0.5399565579133484]\n",
      "Random Forest RMSE Average:  1.0287\n",
      "Random Forest RMSE Standard Deviation:  0.0117\n",
      "Random Forest R2 Average:  0.541\n",
      "Random Forest R2 Standard Deviation:  0.0075\n",
      "RMSE:  [1.2009685316563232, 1.1856725389467517, 1.1742229192996323, 1.1925454811279883, 1.1897084121379078] r2 score: [0.36482067861091716, 0.3813607050923912, 0.41163071470281387, 0.3903779206201339, 0.38730812617984434]\n",
      "SVR RMSE Average:  1.1886\n",
      "SVR RMSE Standard Deviation:  0.0088\n",
      "SVR R2 Average:  0.3871\n",
      "SVR R2 Standard Deviation:  0.0151\n",
      "RMSE:  [1.1509330811455585, 1.1295398774442214, 1.1505330702172838, 1.1489104673733332, 1.1398957342427976] r2 score: [0.41664457464422655, 0.4385499624324427, 0.43513183450922066, 0.43417366320483464, 0.43754042757830935]\n",
      "kNearestNeighbors RMSE Average:  1.144\n",
      "kNearestNeighbors RMSE Standard Deviation:  0.0083\n",
      "kNearestNeighbors R2 Average:  0.4324\n",
      "kNearestNeighbors R2 Standard Deviation:  0.008\n",
      "RMSE:  [0.9960296026266104, 0.9811152698164131, 1.0089936893280196, 1.0054808377508888, 1.0052362469488991] r2 score: [0.5631044841591312, 0.5764077073785453, 0.5655640192269118, 0.5666304606334022, 0.5625813099839532]\n",
      "XGBoost RMSE Average:  0.9994\n",
      "XGBoost RMSE Standard Deviation:  0.0101\n",
      "XGBoost R2 Average:  0.5669\n",
      "XGBoost R2 Standard Deviation:  0.005\n",
      "RMSE:  [1.0472735116884058, 1.0558569532214759, 1.0702209041756348, 1.0934606355226497, 1.0493474779773837] r2 score: [0.5169931016108802, 0.5094106140175535, 0.5112398984347206, 0.48747259528246867, 0.523349885542852]\n",
      "NN_MLP RMSE Average:  1.0632\n",
      "NN_MLP RMSE Standard Deviation:  0.0171\n",
      "NN_MLP R2 Average:  0.5097\n",
      "NN_MLP R2 Standard Deviation:  0.0121\n"
     ]
    }
   ],
   "source": [
    "# Run all the models with the final chosen hyperparameters. \n",
    "model_grids = [{\n",
    "                'alpha': 0.001},\n",
    "               {\n",
    "                'alpha': 3},\n",
    "               {\n",
    "                'alpha': 0.001,\n",
    "                'l1_ratio': 0.99},\n",
    "               {\n",
    "                'n_estimators': 250,\n",
    "                'max_depth': 15},\n",
    "               { \n",
    "                'gamma': 1e-1,\n",
    "                'C': 1e2},\n",
    "               { \n",
    "                'n_neighbors': 15},\n",
    "               { \n",
    "                'max_depth': 6, \n",
    "                'min_child_weight': 3,  \n",
    "                'learning_rate': 0.03, \n",
    "                'n_estimators': 1000, \n",
    "                'subsample': 0.8,  \n",
    "                'colsample_bytree': 0.8, \n",
    "                'gamma': 0.1}, \n",
    "                {\n",
    "                'hidden_layer_sizes': (150),\n",
    "                'alpha': 0.0003, \n",
    "                'max_iter': 300}]\n",
    "\n",
    "# you might want to just do svms and then all other ones\n",
    "for i in range(len(model_list)):\n",
    "\n",
    "    test_scores, best_models, r2_scores = MLpipe_Final_RMSE(X,y,preprocessor,model_list[i], \n",
    "                                                 model_grids[i], 5, names_list[i])\n",
    "    \n",
    "    print(names_list[i], \"RMSE Average: \", np.round(np.mean(test_scores), 4))\n",
    "    print(names_list[i], \"RMSE Standard Deviation: \", np.round(np.std(test_scores), 4))\n",
    "    print(names_list[i], \"R2 Average: \", np.round(np.mean(r2_scores), 4))\n",
    "    print(names_list[i], \"R2 Standard Deviation: \", np.round(np.std(r2_scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Calculating Baseline RMSE / R2 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE Average:  1.5186\n",
      "Baseline RMSE Standard Deviation:  0.0099\n",
      "Baseline R2 Average:  -0.0001\n",
      "Baseline R2 Standard Deviation:  0.0001\n"
     ]
    }
   ],
   "source": [
    "num_seeds = 5\n",
    "random_states = np.linspace(0,100000, num_seeds, dtype=int)\n",
    "test_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for i in range(num_seeds): \n",
    "\n",
    "    # Split Data Randomly \n",
    "    X_other, X_test, y_other, y_test = (train_test_split(X, \n",
    "            y, train_size=0.8, random_state=random_states[i]))\n",
    "\n",
    "    \n",
    "    train_mean = np.ones(y_test.shape) * np.mean(y_other)\n",
    "    rmse = root_mean_squared_error(y_test, train_mean)\n",
    "    r2 = r2_score(y_test, train_mean)\n",
    "    test_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "   \n",
    "print(\"Baseline RMSE Average: \", np.round(np.mean(test_scores), 4))\n",
    "print(\"Baseline RMSE Standard Deviation: \", np.round(np.std(test_scores), 4))\n",
    "print(\"Baseline R2 Average: \", np.round(np.mean(r2_scores), 4))\n",
    "print(\"Baseline R2 Standard Deviation: \", np.round(np.std(r2_scores), 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Store the (Preprocessed) Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467     3.164353\n",
      "8690     3.778224\n",
      "88       2.008600\n",
      "12721    2.201397\n",
      "6415     2.885361\n",
      "           ...   \n",
      "12855    4.177421\n",
      "10005    1.812913\n",
      "16699    3.839227\n",
      "5153     0.602060\n",
      "2820     1.778151\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[ 1.37624999 -0.09003737  0.24160603 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.0388647  -1.2877749  -0.2341902  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.7014794   0.20939702 -0.09989288 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.37624999  0.20939702 -0.08838168 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.0388647  -0.38947175  0.09963457 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.71363528 -0.68890613 -0.2341902  ...  0.          0.\n",
      "   0.        ]]\n",
      "5832     4.253265\n",
      "11340    3.529045\n",
      "24068    3.073352\n",
      "20960    0.778151\n",
      "2364     3.668199\n",
      "           ...   \n",
      "8427     3.602386\n",
      "17721    4.074487\n",
      "10458    0.301030\n",
      "21125    3.579898\n",
      "4827     1.748188\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[ 1.38386412  1.11071976  1.38812802 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.04418037 -0.68537788 -0.11261579 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.04418037 -0.38602827 -0.34379097 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.02512914  1.11071976 -0.35895    ...  0.          0.\n",
      "   0.        ]\n",
      " [-2.69234083 -1.5834267  -0.23009826 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.72354787 -0.08667867  0.17161599 ...  0.          0.\n",
      "   0.        ]]\n",
      "2066     0.903090\n",
      "4744     2.846337\n",
      "9184     0.602060\n",
      "3111     0.301030\n",
      "6183     1.908485\n",
      "           ...   \n",
      "14911    0.301030\n",
      "1176     4.873646\n",
      "19035    0.301030\n",
      "12607    4.232767\n",
      "22667    3.455150\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[-1.32454528 -0.38686576 -0.40721265 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.37184313 -0.08756296  0.37815108 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.66159383 -0.68616856 -0.23012083 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.31339963  0.51104264  0.91327636 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.31339963 -0.38686576 -0.33021621 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.69774602  0.81034544 -0.23012083 ...  0.          0.\n",
      "   0.        ]]\n",
      "2340     3.716087\n",
      "12856    0.602060\n",
      "11278    4.317813\n",
      "7829     3.408918\n",
      "16791    3.335859\n",
      "           ...   \n",
      "4965     2.315970\n",
      "13141    1.924279\n",
      "11153    2.602060\n",
      "198      3.624282\n",
      "549      2.528917\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[-0.65292274 -1.58460957 -0.40011486 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.99161941  1.70371064 -0.42930472 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.04056063 -1.58460957 -0.07172891 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.04056063  0.80689604  0.29314436 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.71795398 -0.38885677 -0.22497569 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.70186396  0.20901963 -0.45484585 ...  0.          0.\n",
      "   0.        ]]\n",
      "16072    4.099715\n",
      "22727    0.778151\n",
      "7846     1.255273\n",
      "11653    2.149219\n",
      "3714     0.477121\n",
      "           ...   \n",
      "20332    6.023454\n",
      "15511    0.477121\n",
      "21970    7.041393\n",
      "19047    3.487563\n",
      "10408    2.933487\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[-2.68479675 -0.9847134  -0.2245217  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.65048683 -0.38539285 -0.51958828 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.36666812  0.51358797  0.0262849  ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.98953849 -0.9847134   0.65330139 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.04477143  1.41256879 -0.35730166 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.72287473 -0.9847134  -0.2245217  ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Make sure this is the same number of seeds\n",
    "num_seeds = 5\n",
    "random_states = np.linspace(0,100000, num_seeds, dtype=int)\n",
    "\n",
    "for i in range(num_seeds): \n",
    "\n",
    "    # Split Data Randomly Same as in pipeline\n",
    "    X_other, X_test, y_other, y_test = (train_test_split(X, \n",
    "            y, train_size=0.8, random_state=random_states[i]))\n",
    "    \n",
    "    preprocessor.fit_transform(X_other)\n",
    "    X_test_pp = preprocessor.transform(X_test)\n",
    "    all_features = num_ftrs + list(preprocessor.transformers_[1][1].get_feature_names_out())\n",
    "    df = pd.DataFrame(X_test_pp, columns=all_features, index=X_test.index)\n",
    "    df[\"y\"] = y_test\n",
    "    print(y_test)\n",
    "    print(X_test_pp)\n",
    "    df.to_csv(path + \"/results/processed_testdf\" + str(i), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
