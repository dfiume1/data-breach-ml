{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the machine learning work for this project. A preprocessing, splitting, and CV pipeline are created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Data Shape:  (24586, 29)\n"
     ]
    }
   ],
   "source": [
    "# Load the data (raw / feature engineered)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = \"/Users/djfiume/Desktop/DSI/1030/data-breach-ml\"\n",
    "data = pd.read_csv(path + \"/data/cleaned_raw_data.csv\", index_col=0)\n",
    "\n",
    "data.head()\n",
    "print(\"Full Data Shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix size: (24586, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    24586.000000\n",
       "mean         5.487421\n",
       "std          3.497903\n",
       "min          0.000000\n",
       "25%          2.079442\n",
       "50%          5.954540\n",
       "75%          7.977366\n",
       "max         21.821878\n",
       "Name: Max Records Impacted, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['Max Records Impacted']\n",
    "\n",
    "data.drop(columns=['Max Records Impacted'],inplace=True)\n",
    "# the unprocessed feature matrix\n",
    "X = data\n",
    "print(f'feature matrix size: {X.shape}')\n",
    "# the feature names\n",
    "ftrs = data.columns\n",
    "\n",
    "# MODEL MAKES MORE SENSE TO PREDICT THE LOGS\n",
    "# ex: predicting 100 records for true 10,000 should be the same as predicting 1,000,000 for true 10,000\n",
    "y = y+1\n",
    "y = np.log(y)\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the Features\n",
    "\n",
    "cat_ftrs = [\"Breach Type\", \"Source\", \"Organization Type\", \"breach_location_state\"]\n",
    "\n",
    "num_ftrs = [\"Reported Year\", \"Reported Month\", \"Days Until Reported\", \"Length of Breach (Days)\", \"IDENTIFIER\",\\\n",
    "            \"COMMERCIAL\", \"BIOMETRIC\", \"HEALTH\", \"INTERNETDATA\", \"GEOLOCATION\", \"RECORDING\", \"EMPLOYMENT\",\\\n",
    "            \"EDUCATION\", \"SENSITIVE-GOV\", \"SENSITIVE-LOGIN\", \"SENSITIVE-GEOLOCATION\", \"SENSITIVE-PROTECTED\",\\\n",
    "            \"SENSITIVE-COMMUNICATIONS\", \"SENSITIVE-DNA\", \"Type UNKN\", \"ENCRYPTED\", \"ENCRYPTED-WITH-DECRYPTIONKEY\",\\\n",
    "            \"UNENCRYPTED\", \"Encrypt UNKN\"]\n",
    "\n",
    "# From the Data README \n",
    "# info_types = [\"IDENTIFIER\", \"COMMERCIAL\", \"BIOMETRIC\", \"HEALTH\", \"INTERNETDATA\", \"GEOLOCATION\", \"RECORDING\", \"EMPLOYMENT\", \"EDUCATION\", \"SENSITIVE-GOV\", \"SENSITIVE-LOGIN\", \"SENSITIVE-GEOLOCATION\", \"SENSITIVE-PROTECTED\", \"SENSITIVE-COMMUNICATIONS\", \"SENSITIVE-DNA\", \"UNKN\"]\n",
    "# encrypt_types = [\"ENCRYPTED\", \"ENCRYPTED-WITH-DECRYPTIONKEY\", \"UNENCRYPTED\"]\n",
    "# breach_types = [\"CARD\", \"HACK\", \"INSD\", \"PHYS\", \"PORT\", \"STAT\", \"DISC\", \"UNKN\"]\n",
    "# org_types = [\"BSF\", \"BSO\", \"BSR\", \"EDU\", \"GOV\", \"MED\", \"NGO\", \"UNKN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Preprocessor \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# one-hot encoder\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='UNKN')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # This is only for the date features.\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "\n",
    "def MLpipe_KFold_RMSE(X, y, preprocessor, ML_algo, param_grid, num_seeds):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 5 folds to other.\n",
    "    The RMSLE (Root Mean Squared Log Error) is minimized in cross-validation.\n",
    "\n",
    "    Args:\n",
    "    X : DataFrame or ndarray\n",
    "        Features for model training.\n",
    "    y : DataFrame or ndarray\n",
    "        Labels/target for model training.\n",
    "    preprocessor : sklearn transformer\n",
    "        The preprocessor object (e.g., ColumnTransformer).\n",
    "    ML_algo : sklearn estimator\n",
    "        The machine learning algorithm (e.g., RandomForestRegressor).\n",
    "    param_grid : dict\n",
    "        Grid of parameters for GridSearchCV.\n",
    "    num_seeds : int\n",
    "        Number of random seeds to use for cross-validation.\n",
    "    save_model : bool, default False\n",
    "        Whether to save the best model and predictions.\n",
    "    name: string, default None\n",
    "        What the model name is to name the filenames\n",
    "\n",
    "    Returns:\n",
    "    test_scores : list\n",
    "        List of test RMSE scores.\n",
    "    best_models : list\n",
    "        List of best model parameters from GridSearchCV.\n",
    "    r2_scores : list\n",
    "        List of RÂ² scores for the test set.\n",
    "    '''\n",
    "     \n",
    "    test_scores = []\n",
    "    r2_scores = []\n",
    "    best_models = []\n",
    "\n",
    "    # Loops through 5 different random states. This is to ensure the best model\n",
    "    # on average is picked. They are fixed for reproducability. \n",
    "    random_states = np.linspace(0,100000, num_seeds, dtype=int)\n",
    "    \n",
    "    for i in range(num_seeds): \n",
    "\n",
    "        # Split Data Randomly \n",
    "        X_other, X_test, y_other, y_test = (train_test_split(X, \n",
    "            y, train_size=0.8, random_state=random_states[i]))\n",
    "\n",
    "        # Fits a model using GridSearchCV with KFold and the predefined Preprocessor \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=random_states[i]) \n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', ML_algo)\n",
    "        ])\n",
    "        \n",
    "        grid_search = GridSearchCV(pipeline, param_grid, \n",
    "                            scoring=\"neg_root_mean_squared_error\", cv=kf, verbose=2) # you can turn this off\n",
    "        grid_search.fit(X_other, y_other)\n",
    "\n",
    "        # Calculate the model's error on the test set \n",
    "        y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        print(rmse)\n",
    "        print(r2)\n",
    "        test_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        best_models.append(best_params)\n",
    "\n",
    "        # Only need to print this once, can use for debugging\n",
    "        # if random_state == 0:\n",
    "            # print(\"Train_Inputs Shape:\", X_other.shape)\n",
    "            # print(\"Train_Labels Shape:\", y_other.shape)\n",
    "            # print(\"Test_Inputs Shape:\", X_test.shape)\n",
    "            # print(\"Test_Labels Shape:\", y_test.shape)\n",
    "\n",
    "            # print(\"GridSearch\", grid_search.cv_results_)\n",
    "        \n",
    "        # print(\"Random State: \", random_state, \" RMSE: \", rmse, \n",
    "        #       \" Best Model:\", best_params)\n",
    "\n",
    "    print(\"RMSE: \", test_scores, \"\\n Models: \", best_models, \"r2 score:\", r2_scores)\n",
    "    return test_scores, best_models, r2_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the pipeline on regression algorithims for CV / hyperparamter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune individual models in the first cell. Only run the last cell when you have narrowed down your search (it takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] END ...................................model__alpha=1.0; total time=   0.2s\n",
      "[CV] END ...................................model__alpha=1.0; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=1.0; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=1.0; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=1.0; total time=   0.1s\n",
      "[CV] END ....................model__alpha=1.2142857142857142; total time=   0.1s\n",
      "[CV] END ....................model__alpha=1.2142857142857142; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.2142857142857142; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.2142857142857142; total time=   0.1s\n",
      "[CV] END ....................model__alpha=1.2142857142857142; total time=   0.1s\n",
      "[CV] END ....................model__alpha=1.4285714285714286; total time=   0.1s\n",
      "[CV] END ....................model__alpha=1.4285714285714286; total time=   0.1s\n",
      "[CV] END ....................model__alpha=1.4285714285714286; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.4285714285714286; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.4285714285714286; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.6428571428571428; total time=   0.1s\n",
      "[CV] END ....................model__alpha=1.6428571428571428; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.6428571428571428; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.6428571428571428; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.6428571428571428; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.8571428571428572; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.8571428571428572; total time=   0.1s\n",
      "[CV] END ....................model__alpha=1.8571428571428572; total time=   0.1s\n",
      "[CV] END ....................model__alpha=1.8571428571428572; total time=   0.2s\n",
      "[CV] END ....................model__alpha=1.8571428571428572; total time=   0.1s\n",
      "[CV] END .....................model__alpha=2.071428571428571; total time=   0.1s\n",
      "[CV] END .....................model__alpha=2.071428571428571; total time=   0.1s\n",
      "[CV] END .....................model__alpha=2.071428571428571; total time=   0.2s\n",
      "[CV] END .....................model__alpha=2.071428571428571; total time=   0.2s\n",
      "[CV] END .....................model__alpha=2.071428571428571; total time=   0.2s\n",
      "[CV] END ....................model__alpha=2.2857142857142856; total time=   0.2s\n",
      "[CV] END ....................model__alpha=2.2857142857142856; total time=   0.2s\n",
      "[CV] END ....................model__alpha=2.2857142857142856; total time=   0.2s\n",
      "[CV] END ....................model__alpha=2.2857142857142856; total time=   0.2s\n",
      "[CV] END ....................model__alpha=2.2857142857142856; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=2.5; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=2.5; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=2.5; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=2.5; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=2.5; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.7142857142857144; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.7142857142857144; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.7142857142857144; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.7142857142857144; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.7142857142857144; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.9285714285714284; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.9285714285714284; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.9285714285714284; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.9285714285714284; total time=   0.1s\n",
      "[CV] END ....................model__alpha=2.9285714285714284; total time=   0.2s\n",
      "[CV] END .....................model__alpha=3.142857142857143; total time=   0.2s\n",
      "[CV] END .....................model__alpha=3.142857142857143; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.142857142857143; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.142857142857143; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.142857142857143; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.357142857142857; total time=   0.2s\n",
      "[CV] END .....................model__alpha=3.357142857142857; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.357142857142857; total time=   0.2s\n",
      "[CV] END .....................model__alpha=3.357142857142857; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.357142857142857; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.571428571428571; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.571428571428571; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.571428571428571; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.571428571428571; total time=   0.1s\n",
      "[CV] END .....................model__alpha=3.571428571428571; total time=   0.1s\n",
      "[CV] END ....................model__alpha=3.7857142857142856; total time=   0.1s\n",
      "[CV] END ....................model__alpha=3.7857142857142856; total time=   0.1s\n",
      "[CV] END ....................model__alpha=3.7857142857142856; total time=   0.1s\n",
      "[CV] END ....................model__alpha=3.7857142857142856; total time=   0.1s\n",
      "[CV] END ....................model__alpha=3.7857142857142856; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=4.0; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=4.0; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=4.0; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=4.0; total time=   0.1s\n",
      "[CV] END ...................................model__alpha=4.0; total time=   0.1s\n",
      "2.5694763305883086\n",
      "0.4516081896090539\n",
      "RMSE:  [2.5694763305883086] \n",
      " Models:  [{'model__alpha': 2.9285714285714284}] r2 score: [0.4516081896090539]\n",
      "[{'model__alpha': 2.9285714285714284}]\n",
      "L2_Linerar_Regression RMSE Average:  2.5695\n",
      "L2_Linerar_Regression RMSE Standard Deviation:  0.0\n",
      "L2_Linerar_Regression R2 Average:  0.4516\n",
      "L2_Linerar_Regression R2 Standard Deviation:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Use to determine the hyperparameters for the final run \n",
    "\n",
    "names_list = [\"L1_Linerar_Regression\", # i=0\n",
    "              \"L2_Linerar_Regression\", # 1\n",
    "              \"Elastic-Net_Linerar_Regression\", # 2\n",
    "              \"Random Forest\", # 3\n",
    "              \"SVR\", # 4\n",
    "              \"kNearestNeighbors\", # 5\n",
    "              \"XGBoost\", # 6\n",
    "              \"NN_MLP\"] # 7\n",
    "model_list = [Lasso(max_iter=500), \n",
    "              Ridge(max_iter=500), \n",
    "              ElasticNet(max_iter=500), \n",
    "              RandomForestRegressor(), \n",
    "              SVR(),\n",
    "              KNeighborsRegressor(),\n",
    "              XGBRegressor(),\n",
    "              MLPRegressor(learning_rate=\"adaptive\", batch_size=\"auto\", solver=\"adam\", early_stopping=True)]\n",
    "\n",
    "# adjust the grids as you go \n",
    "model_grids = [{\n",
    "                'model__alpha': np.logspace(-4, -2, 10)},\n",
    "               {\n",
    "                'model__alpha': np.linspace(1, 4, 15)},\n",
    "               {\n",
    "                'model__alpha': np.logspace(-4, -2, 5),\n",
    "                'model__l1_ratio' : np.linspace(0.01,0.99,5)},\n",
    "               {\n",
    "                'model__n_estimators': [100, 150, 200],\n",
    "                'model__max_depth': [10, 15, 20]},\n",
    "               { \n",
    "                'model__gamma': [1e-3, 1e-2, 1e-1, 1e0],\n",
    "                'model__C': [1e-1, 1e0, 1e1, 1e2, 1e3]},\n",
    "               { \n",
    "                'model__n_neighbors': [1,3,5,7,10,15,20,25,30,40,50,75,100]},\n",
    "               {\n",
    "                'model__max_depth': [6], \n",
    "                'model__min_child_weight': [3],  \n",
    "                'model__learning_rate': [0.03],  # Tune these two, then above two, then the below 2 and then gamma\n",
    "                'model__n_estimators': [1000], \n",
    "                'model__subsample': [0.8],  \n",
    "                'model__colsample_bytree': [0.8], \n",
    "                'model__gamma': [0,0.1,0.2]}, \n",
    "                {\n",
    "                'model__hidden_layer_sizes': [(150,2)],\n",
    "                'model__alpha': [0.001, 0.0003, 0.001], \n",
    "                'model__max_iter': [300]}]\n",
    "\n",
    "# Pick a model type, run and print results\n",
    "i = 1\n",
    "num_seeds = 1 # can use 1 to narrow range, otherwise some models (SVM) will take a long time \n",
    "test_scores, best_models, r2_scores = MLpipe_KFold_RMSE(X,y,preprocessor,model_list[i], model_grids[i], num_seeds)\n",
    "print(best_models)\n",
    "print(names_list[i], \"RMSE Average: \", np.round(np.mean(test_scores), 4))\n",
    "print(names_list[i], \"RMSE Standard Deviation: \", np.round(np.std(test_scores), 4))\n",
    "print(names_list[i], \"R2 Average: \", np.round(np.mean(r2_scores), 4))\n",
    "print(names_list[i], \"R2 Standard Deviation: \", np.round(np.std(r2_scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Testing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell takes the chosen hyperparamters and runs the models with an 80/20 split over 5 random seeds. It saves each model and the predictions to results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/djfiume/Desktop/DSI/1030/data-breach-ml\"\n",
    "\n",
    "def MLpipe_Final_RMSE(X, y, preprocessor, ML_algo, param_grid, num_seeds, name=None):\n",
    "    '''\n",
    "    This function splits the data to train/test (80/20). It then trains the model and tests it\n",
    "    for a set number of random seeds, saves the models and predictions, and returns the results  \n",
    "    \n",
    "    Args:\n",
    "    X : DataFrame or ndarray\n",
    "        Features for model training.\n",
    "    y : DataFrame or ndarray\n",
    "        Labels/target for model training.\n",
    "    preprocessor : sklearn transformer\n",
    "        The preprocessor object (e.g., ColumnTransformer).\n",
    "    ML_algo : sklearn estimator\n",
    "        The machine learning algorithm (e.g., RandomForestRegressor).\n",
    "    param_grid : dict\n",
    "        Grid of parameters for GridSearchCV.\n",
    "    num_seeds : int\n",
    "        Number of random seeds to use for cross-validation.\n",
    "    name: string, default None\n",
    "        What the model name is to name the filenames\n",
    "\n",
    "    Returns:\n",
    "    test_scores : list\n",
    "        List of test RMSE scores.\n",
    "    best_models : list\n",
    "        List of best model parameters from GridSearchCV.\n",
    "    r2_scores : list\n",
    "        List of RÂ² scores for the test set.\n",
    "    '''\n",
    "     \n",
    "    test_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "\n",
    "    # Loops through a given number of different random states. This is to ensure the best model\n",
    "    # on average is picked. They are fixed for reproducability (if you choose the same # of seeds). \n",
    "    random_states = np.linspace(0,100000, num_seeds, dtype=int)\n",
    "    \n",
    "    for i in range(num_seeds): \n",
    "\n",
    "        # Split Data Randomly \n",
    "        X_train, X_test, y_train, y_test = (train_test_split(X, \n",
    "            y, train_size=0.8, random_state=random_states[i]))\n",
    "\n",
    "        model = ML_algo.set_params(**param_grid)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Calculate the model's error on the test set \n",
    "        y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        test_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "\n",
    "        # Only need to print this once, can use for debugging\n",
    "        # if random_state == 0:\n",
    "            # print(\"Train_Inputs Shape:\", X_other.shape)\n",
    "            # print(\"Train_Labels Shape:\", y_other.shape)\n",
    "            # print(\"Test_Inputs Shape:\", X_test.shape)\n",
    "            # print(\"Test_Labels Shape:\", y_test.shape)\n",
    "\n",
    "            # print(\"GridSearch\", grid_search.cv_results_)\n",
    "        \n",
    "        # print(\"Random State: \", random_state, \" RMSE: \", rmse, \n",
    "        #       \" Best Model:\", best_params)\n",
    "    \n",
    "        # Optionally save the best model and its predictions\n",
    "        if name is not None:\n",
    "            model_file = path + \"/results/\" + name + str(i) + \".pkl\"\n",
    "            pred_file = path + \"/results/\" + name + str(i) + \".npy\"\n",
    "            joblib.dump(pipeline, model_file)\n",
    "            np.save(pred_file, y_pred)\n",
    "            # print(f\"Best model saved as {model_file}\")\n",
    "            # print(f\"Predictions saved as {pred_file}\")\n",
    "        \n",
    "\n",
    "    print(\"RMSE: \", test_scores, \"r2 score:\", r2_scores)\n",
    "    return test_scores, best_models, r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  [2.40315135816962, 2.4099688842548197, 2.438164669760512, 2.4710328947443476, 2.4184980731018797] \n",
      " Models:  [{'model__alpha': 0.0003, 'model__hidden_layer_sizes': (150, 2), 'model__max_iter': 500}] r2 score: [0.5203063522158199, 0.51794180239491, 0.5215422678539352, 0.5063303116765032, 0.522447448778617]\n",
      "NN_MLP RMSE Average:  2.4282\n",
      "NN_MLP RMSE Standard Deviation:  0.0244\n",
      "NN_MLP R2 Average:  0.5177\n",
      "NN_MLP R2 Standard Deviation:  0.0059\n"
     ]
    }
   ],
   "source": [
    "# Run all the models with the final chosen hyperparameters. \n",
    "model_grids = [{\n",
    "                'alpha': 0.001},\n",
    "               {\n",
    "                'alpha': 3},\n",
    "               {\n",
    "                'alpha': 0.001,\n",
    "                'l1_ratio': 0.99},\n",
    "               {\n",
    "                'n_estimators': 250,\n",
    "                'max_depth': 15},\n",
    "               { \n",
    "                'gamma': 1e-1,\n",
    "                'C': 1e2},\n",
    "               { \n",
    "                'n_neighbors': 15},\n",
    "               { \n",
    "                'max_depth': 6, \n",
    "                'min_child_weight': 3,  \n",
    "                'learning_rate': 0.03, \n",
    "                'n_estimators': 1000, \n",
    "                'subsample': 0.8,  \n",
    "                'colsample_bytree': 0.8, \n",
    "                'gamma': 0.1}, \n",
    "                {\n",
    "                'hidden_layer_sizes': (150),\n",
    "                'alpha': 0.0003, \n",
    "                'max_iter': 300}]\n",
    "\n",
    "# you might want to just do svms and then all other ones\n",
    "for i in range(7,8):\n",
    "\n",
    "    test_scores, best_models, r2_scores = MLpipe_Final_RMSE(X,y,preprocessor,model_list[i], \n",
    "                                                 model_grids[i], 5, names_list[i])\n",
    "    \n",
    "    print(names_list[i], \"RMSE Average: \", np.round(np.mean(test_scores), 4))\n",
    "    print(names_list[i], \"RMSE Standard Deviation: \", np.round(np.std(test_scores), 4))\n",
    "    print(names_list[i], \"R2 Average: \", np.round(np.mean(r2_scores), 4))\n",
    "    print(names_list[i], \"R2 Standard Deviation: \", np.round(np.std(r2_scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Calculating Baseline RMSE / R2 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE Average:  3.4967\n",
      "Baseline RMSE Standard Deviation:  0.0227\n",
      "Baseline R2 Average:  -0.0001\n",
      "Baseline R2 Standard Deviation:  0.0001\n"
     ]
    }
   ],
   "source": [
    "num_seeds = 5\n",
    "random_states = np.linspace(0,100000, num_seeds, dtype=int)\n",
    "test_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for i in range(num_seeds): \n",
    "\n",
    "    # Split Data Randomly \n",
    "    X_other, X_test, y_other, y_test = (train_test_split(X, \n",
    "            y, train_size=0.8, random_state=random_states[i]))\n",
    "\n",
    "    \n",
    "    train_mean = np.ones(y_test.shape) * np.mean(y_other)\n",
    "    rmse = root_mean_squared_error(y_test, train_mean)\n",
    "    r2 = r2_score(y_test, train_mean)\n",
    "    test_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "   \n",
    "print(\"Baseline RMSE Average: \", np.round(np.mean(test_scores), 4))\n",
    "print(\"Baseline RMSE Standard Deviation: \", np.round(np.std(test_scores), 4))\n",
    "print(\"Baseline R2 Average: \", np.round(np.mean(r2_scores), 4))\n",
    "print(\"Baseline R2 Standard Deviation: \", np.round(np.std(r2_scores), 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Store the (Preprocessed) Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467     7.286192\n",
      "8690     8.699681\n",
      "88       4.624973\n",
      "12721    5.068904\n",
      "6415     6.643790\n",
      "           ...   \n",
      "12855    9.618867\n",
      "10005    4.174387\n",
      "16699    8.840146\n",
      "5153     1.386294\n",
      "2820     4.094345\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[ 1.37624999 -0.09003737  0.24160603 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.0388647  -1.2877749  -0.2341902  ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.7014794   0.20939702 -0.09989288 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.37624999  0.20939702 -0.08838168 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.0388647  -0.38947175  0.09963457 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.71363528 -0.68890613 -0.2341902  ...  0.          0.\n",
      "   0.        ]]\n",
      "5832     9.793505\n",
      "11340    8.125927\n",
      "24068    7.076654\n",
      "20960    1.791759\n",
      "2364     8.446341\n",
      "           ...   \n",
      "8427     8.294799\n",
      "17721    9.381854\n",
      "10458    0.693147\n",
      "21125    8.243019\n",
      "4827     4.025352\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[ 1.38386412  1.11071976  1.38812802 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.04418037 -0.68537788 -0.11261579 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.04418037 -0.38602827 -0.34379097 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.02512914  1.11071976 -0.35895    ...  0.          0.\n",
      "   0.        ]\n",
      " [-2.69234083 -1.5834267  -0.23009826 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.72354787 -0.08667867  0.17161599 ...  0.          0.\n",
      "   0.        ]]\n",
      "2066      2.079442\n",
      "4744      6.553933\n",
      "9184      1.386294\n",
      "3111      0.693147\n",
      "6183      4.394449\n",
      "           ...    \n",
      "14911     0.693147\n",
      "1176     11.221985\n",
      "19035     0.693147\n",
      "12607     9.746307\n",
      "22667     7.955776\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[-1.32454528 -0.38686576 -0.40721265 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.37184313 -0.08756296  0.37815108 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.66159383 -0.68616856 -0.23012083 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.31339963  0.51104264  0.91327636 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.31339963 -0.38686576 -0.33021621 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.69774602  0.81034544 -0.23012083 ...  0.          0.\n",
      "   0.        ]]\n",
      "2340     8.556606\n",
      "12856    1.386294\n",
      "11278    9.942131\n",
      "7829     7.849324\n",
      "16791    7.681099\n",
      "           ...   \n",
      "4965     5.332719\n",
      "13141    4.430817\n",
      "11153    5.991465\n",
      "198      8.345218\n",
      "549      5.823046\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[-0.65292274 -1.58460957 -0.40011486 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.99161941  1.70371064 -0.42930472 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.04056063 -1.58460957 -0.07172891 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.04056063  0.80689604  0.29314436 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.71795398 -0.38885677 -0.22497569 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.70186396  0.20901963 -0.45484585 ...  0.          0.\n",
      "   0.        ]]\n",
      "16072     9.439943\n",
      "22727     1.791759\n",
      "7846      2.890372\n",
      "11653     4.948760\n",
      "3714      1.098612\n",
      "           ...    \n",
      "20332    13.869516\n",
      "15511     1.098612\n",
      "21970    16.213406\n",
      "19047     8.030410\n",
      "10408     6.754604\n",
      "Name: Max Records Impacted, Length: 4918, dtype: float64\n",
      "[[-2.68479675 -0.9847134  -0.2245217  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.65048683 -0.38539285 -0.51958828 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.36666812  0.51358797  0.0262849  ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.98953849 -0.9847134   0.65330139 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.04477143  1.41256879 -0.35730166 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.72287473 -0.9847134  -0.2245217  ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "num_seeds = 5\n",
    "random_states = np.linspace(0,100000, num_seeds, dtype=int)\n",
    "\n",
    "for i in range(num_seeds): \n",
    "\n",
    "    # Split Data Randomly Same as in pipeline\n",
    "    X_other, X_test, y_other, y_test = (train_test_split(X, \n",
    "            y, train_size=0.8, random_state=random_states[i]))\n",
    "    \n",
    "    preprocessor.fit_transform(X_other)\n",
    "    X_test_pp = preprocessor.transform(X_test)\n",
    "    all_features = num_ftrs + list(preprocessor.transformers_[1][1].get_feature_names_out())\n",
    "    df = pd.DataFrame(X_test_pp, columns=all_features, index=X_test.index)\n",
    "    df[\"y\"] = y_test\n",
    "    print(y_test)\n",
    "    print(X_test_pp)\n",
    "    df.to_csv(path + \"/results/processed_testdf\" + str(i), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
